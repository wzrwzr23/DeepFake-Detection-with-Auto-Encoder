{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l_Uw36LMXWfR"
      },
      "outputs": [],
      "source": [
        "from xception import Xception, pretrained_settings\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "xception_path = 'checkpoints/xception-b5690688.pth'\n",
        "def xception(num_classes=1000, pretrained='imagenet'):\n",
        "    model = Xception(num_classes=num_classes)\n",
        "    if pretrained:\n",
        "        settings = pretrained_settings['xception'][pretrained]\n",
        "        assert num_classes == settings['num_classes'], \\\n",
        "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
        "\n",
        "        state_dict = torch.load(xception_path)\n",
        "        for name, weights in state_dict.items():\n",
        "            if 'pointwise' in name:\n",
        "                state_dict[name] = weights.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "        model.input_space = settings['input_space']\n",
        "        model.input_size = settings['input_size']\n",
        "        model.input_range = settings['input_range']\n",
        "        model.mean = settings['mean']\n",
        "        model.std = settings['std']\n",
        "\n",
        "    # TODO: ugly\n",
        "    model.last_linear = model.fc\n",
        "    del model.fc\n",
        "    return model\n",
        "\n",
        "\n",
        "class TransferModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple transfer learning model that takes an imagenet pretrained model with\n",
        "    a fc layer as base model and retrains a new fc layer for num_out_classes\n",
        "    \"\"\"\n",
        "    def __init__(self, model, num_out_classes=2, dropout=0.0):\n",
        "        super(TransferModel, self).__init__()\n",
        "        self.model = model\n",
        "        # Replace fc\n",
        "        num_ftrs = self.model.last_linear.in_features\n",
        "        if not dropout:\n",
        "            self.model.last_linear = nn.Linear(num_ftrs, num_out_classes)\n",
        "        else:\n",
        "            print('Using dropout', dropout)\n",
        "            self.model.last_linear = nn.Sequential(\n",
        "                nn.Dropout(p=dropout),\n",
        "                nn.Linear(num_ftrs, num_out_classes)\n",
        "            )\n",
        "\n",
        "         # Initialize the loss function\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pixel_values, labels=None):\n",
        "        logits = self.model(pixel_values)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        # Return loss and other model-specific outputs\n",
        "        return (loss, logits) if loss is not None else logit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mjJprkKAXc-9"
      },
      "outputs": [],
      "source": [
        "old_model = xception()\n",
        "model = TransferModel(model=old_model,\n",
        "                             num_out_classes=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "PzOn1MVUXgwJ",
        "outputId": "a1d9c3ea-0f4a-4b62-d869-05ea799b7d74"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image, ImageFile\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Allow loading of truncated images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "def shuffled_image_paths(folder_true, folder_false):\n",
        "   # Gather true and false paths\n",
        "    true_paths = [{'path': os.path.join(folder_true, f), 'label': 'Real'} for f in os.listdir(folder_true) if f.endswith(('jpg', 'png', 'jpeg'))]\n",
        "    false_paths = [{'path': os.path.join(folder_false, f), 'label': 'Fake'} for f in os.listdir(folder_false) if f.endswith(('jpg', 'png', 'jpeg'))]\n",
        "\n",
        "    all_paths = true_paths + false_paths\n",
        "    random.shuffle(all_paths)  # Shuffle the combined list\n",
        "    df = pd.DataFrame(all_paths)\n",
        "    return df\n",
        "\n",
        "from datasets import Dataset, Features, Value, ClassLabel\n",
        "\n",
        "def create_path_label_dataset(folder_true, folder_false):\n",
        "    paths_labels = shuffled_image_paths(folder_true, folder_false)\n",
        "\n",
        "    # Define dataset features\n",
        "    features = Features({\n",
        "        'path': Value('string'),\n",
        "        'label': ClassLabel(names=['Real', 'Fake']),\n",
        "    })\n",
        "\n",
        "    # Create the dataset\n",
        "    dataset = Dataset.from_pandas(paths_labels, features=features)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
        "\n",
        "normalize = Normalize(mean=old_model.mean, std=old_model.std)\n",
        "size = old_model.input_size[1:]\n",
        "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])\n",
        "\n",
        "def transforms(examples):\n",
        "    images = [Image.open(path).convert(\"RGB\") for path in examples['path']]\n",
        "    examples[\"pixel_values\"] = [_transforms(img) for img in images]\n",
        "    del examples[\"path\"]\n",
        "    return examples\n",
        "\n",
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UgEC6tYSXhTx"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'images'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m folder_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m folder_false \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/fake\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_path_label_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_false\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mwith_transform(transforms)\n",
            "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mcreate_path_label_dataset\u001b[0;34m(folder_true, folder_false)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_path_label_dataset\u001b[39m(folder_true, folder_false):\n\u001b[0;32m---> 22\u001b[0m     paths_labels \u001b[38;5;241m=\u001b[39m \u001b[43mshuffled_image_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_false\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Define dataset features\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     features \u001b[38;5;241m=\u001b[39m Features({\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: Value(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: ClassLabel(names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFake\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     28\u001b[0m     })\n",
            "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mshuffled_image_paths\u001b[0;34m(folder_true, folder_false)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffled_image_paths\u001b[39m(folder_true, folder_false):\n\u001b[1;32m     10\u001b[0m    \u001b[38;5;66;03m# Gather true and false paths\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     true_paths \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_true, f), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_true\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[1;32m     12\u001b[0m     false_paths \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_false, f), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFake\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_false) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[1;32m     14\u001b[0m     all_paths \u001b[38;5;241m=\u001b[39m true_paths \u001b[38;5;241m+\u001b[39m false_paths\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images'"
          ]
        }
      ],
      "source": [
        "folder_true = 'images'\n",
        "folder_false = 'images/fake'\n",
        "\n",
        "dataset = create_path_label_dataset(folder_true, folder_false)\n",
        "dataset = dataset.train_test_split(test_size=0.2)\n",
        "dataset = dataset.with_transform(transforms)\n",
        "\n",
        "labels = dataset['train'].features[\"label\"].names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "6n_ulDNPXj0U",
        "outputId": "650a37cc-77a0-44ab-80ec-d871cf3660e1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7da12c7450748ea931e713dd826f2d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     11\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     12\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepfake-0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     remove_unused_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m---> 29\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m,\n\u001b[1;32m     30\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     31\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     32\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     33\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     34\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     35\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"deepfake-0\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTFpm09CXlw2"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMQ-VyluXoG7"
      },
      "outputs": [],
      "source": [
        "model(transforms([Image.open(dataset['train'][0]['path'])]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
